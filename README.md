<!-- README.md â€“ Enhanced Semantic Search for E-Commerce -->
ğŸ›ï¸ Enhanced Semantic Search for E-Commerce
===========================================

![image](https://github.com/user-attachments/assets/74afc582-6772-4639-b11c-e07fab5af660)

**Problem:**  
Traditional search chops â€œred floral dress under 200 AEDâ€ into isolated keywordsâ€”often showing irrelavant results.

**Solution:**  
Our semantic engine reads the full intent (floral dress + red + garden party + â‰¤ 200 AED) and returns exactly those dresses, with clear â€œwhy this resultâ€ labels and instant virtual try-on.

ğŸš€ Project Overview
-------------------

Traditional e-commerce search engines fail to understand shopper *intent*. Searching for a â€œpastel dressâ€ might return nail polish. We fix that.

**This system empowers users to search using:**
- ğŸ“ Natural language queries (â€œfloral red dress under AED 200â€)
- ğŸ–¼ï¸ Images (upload a product photo or outfit reference)
- âœ¨ Or both, simultaneously

The engine fuses text + image embeddings and in-loop ratings/price filters to deliver *precise, explainable* resultsâ€”backed by an immersive virtual try-on experience.

ğŸ¯ The Real Problem
-------------------

Traditional search engines treat queries as bags of keywords.

*   ğŸ”´ â€œPastel clothesâ€ â†’ returns nail polish bottles on the Most Popualr Fashion store site in UAE

![Screenshot 2025-05-20 153410](https://github.com/user-attachments/assets/afe9e65c-9e1a-4471-8f67-f6f4062e64ec)

    
*   ğŸ•’ Shoppers spend extra minutes refining queries or leave frustrated
    
*   ğŸ“‰ Retailers lose sales and face higher bounce rates
    

**We solve this by**:

1.  Understanding **context**: identifying occasions, styles, and nuances.
    
2.  Fusing **text + visual intent** in a single unified embedding.
    
3.  Offering **interactive try-on** to boost confidence and reduce returns.

    
## ğŸ”‘ Key Features

### ğŸ” Multimodal Semantic Search  
- Fuse text + image + reviews into unified CLIP-based embeddings  
- Instant vector-based retrieval on 45k+ items using FAISS

### ğŸ§  Explainable Recommendations  
- â€œWhy we recommend thisâ€ panels powered by rule-engine + Gemini polish  
- Shows attributes, match rationale, and confidence tags

### ğŸ‘— Try Before You Buy â€“ Virtual Try-On  
- Upload a selfie, see yourself in any dress  
- Pipeline: UÂ²-Net â†’ OpenPose â†’ CP-VTON â†’ GAN â†’ Blending

### âš¡ FastAPI Backend + Intuitive React UI  
- 100ms latency on consumer-grade hardware  
- Chips, loaders, patch previews, tooltips, and fallback handling

## ğŸ› ï¸ Tech Stack

| Layer                 | Technologies Used                                                                            |
|----------------------|----------------------------------------------------------------------------------------------|
| **Models**     | OpenCLIP (ViT-B/32), BLIP, Gemini API, FAISS, CP-VTON, UÂ²-Net, OpenPose                      |
| **Backend (API)**     | Python 3.11, FastAPI, Pydantic, FAISS, torch, NumPy                                          |
| **Frontend (UI)**     | React 18, TypeScript, Node.js, TailwindCSS, Vite, Lucide Icons                         |
| **Storage & Assets**  | MongoDB, Local asset store for segmented masks and try-on outputs                            |
| **Dataset**     | Selenium (for scraping), Python scripts (for augmentation & indexing dataset), XGBoost (caption ranking) |


ğŸ—ï¸ System Architecture
-----------------------

    flowchart LR
      subgraph Preprocessing
        A[Raw Catalog & Images]
        A --> B[Data Cleaning & Normalization]
        B --> C[BLIP Captioning & Review Generation]
        C --> D[Embedding: OpenCLIP Text & Image]
        D --> E[FAISS FlatIP Index Build]
      end
    
      subgraph Query Pipeline
        Q[User Query: Text / Image]
        Q --> F[Embed Query via OpenCLIP]
        F --> G[FAISS Search (Top-k)]
        G --> H[Facet Reranking & Explainable Filter]
        H --> I[FastAPI â†’ JSON Response]
        I --> J[React Frontend]
        J -->|"Try On"| K[Virtual Try-On Service]
        K --> J
      end

## ğŸ¥ Live Demo 

[ğŸ‘€âœ¨ Click here to explore our project! ](https://www.canva.com/design/DAGodjKFnY0/z5C1IPc4cQ99Euixpy3PdQ/watch?utm_content=DAGodjKFnY0&utm_campaign=designshare&utm_medium=link2&utm_source=uniquelinks&utlId=h29ac98f660)


## ğŸ“Š Performance & Benchmarks (30-user evaluation)

![image](https://github.com/user-attachments/assets/8b3200e5-7600-4aff-811c-b499e28f251b)

| Metric                              | Outcome                                      |
|-------------------------------------|----------------------------------------------|
| **User preference rate**            | 60% chose our system over baseline methods   |
| **Time to first relevant result**   | â†“ 50% (1.2s vs. 2.8s in keyword search)      |
| **Trust Score (Explainability)**    | 4.6 / 5 average                              |
| **Post Try-On Add-to-Cart Rate**    | 28% (2x higher than baseline search UX)      |


ğŸ›¤ï¸ Roadmap & Future Work
-------------------------

*    Real-time personalization via user-click feedback loop
    
*    Voice-based search integration


* * *

Built with â¤ï¸ by **Shafeeqa Fathima Jahangir**, Final-Year CS @ University of West London.


